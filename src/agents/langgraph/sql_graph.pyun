import os
import psycopg2
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from src.agents.utils.model_factory import get_model
from src.config.langsmith_init import init_langsmith
from langsmith import traceable

# ======================
# Inicialización global
# ======================

load_dotenv()
init_langsmith()

# ======================
# Diccionario de KPIs
# ======================

KPI_ALIASES = {
    "ventas promedio": "kpi_avg_sales_volume",
    "volumen de ventas": "kpi_avg_sales_volume",
    "promedio de ventas": "kpi_avg_sales_volume",
    "closing rate": "kpi_closing_rate",
    "tasa de cierre": "kpi_closing_rate",
    "ventas por ciudad": "kpi_sales_volume_by_city",
    "industria": "industry_benchmarks",
    "comparación industria": "industry_benchmarks",
    "sector landscaping": "industry_benchmarks",
    "benchmark": "industry_benchmarks"
}

# ======================
# Funciones auxiliares
# ======================

def fetch_kpi_definition(kpi_name: str):
    """Busca el KPI por nombre en la capa semántica (ai.table_context)."""
    conn = psycopg2.connect(
        host=os.getenv("DB_HOST"),
        port=os.getenv("DB_PORT"),
        dbname=os.getenv("DB_NAME"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        sslmode="require"
    )
    cur = conn.cursor()
    cur.execute("""
        SELECT table_name, description
        FROM ai.table_context
        WHERE table_type = 'kpi'
        AND table_name ILIKE %s
        LIMIT 1;
    """, (f"%{kpi_name}%",))
    result = cur.fetchone()
    conn.close()
    if not result:
        return None
    return {"kpi_name": result[0], "description": result[1]}


def execute_kpi_query(kpi_name: str):
    """Ejecuta la consulta del KPI correspondiente (nombre flexible y seguro)."""
    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT"),
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD"),
            sslmode="require"
        )
        cur = conn.cursor()

        safe_name = kpi_name.strip().lower().replace(" ", "_")
        if safe_name.startswith("kpi_"):
            full_table = f"ai.{safe_name}"
        else:
            cur.execute("""
                SELECT table_name FROM ai.table_context
                WHERE table_name ILIKE %s LIMIT 1;
            """, (f"%{safe_name}%",))
            found = cur.fetchone()
            if found:
                full_table = f"ai.{found[0]}"
            else:
                full_table = f"ai.kpi_{safe_name}"

        print(f"Ejecutando KPI: {full_table}")
        cur.execute(f"SELECT * FROM {full_table} LIMIT 10;")
        rows = cur.fetchall()
        colnames = [desc[0] for desc in cur.description]
        conn.close()

        if not rows:
            print("KPI sin resultados.")
            return {"columns": colnames, "rows": [], "message": "KPI sin filas."}

        print(f"{len(rows)} filas devueltas.")
        return {"columns": colnames, "rows": rows}

    except Exception as e:
        print(f"Error en execute_kpi_query: {e}")
        return {"error": str(e), "columns": [], "rows": []}

# ======================
# Nodos del grafo
# ======================


@traceable(run_type="tool", name="KPI Node")
def kpi_node(state):
    """Ejecuta la lógica KPI con detección semántica y fallback automático.
    - Si detecta un alias explícito → usa el KPI correspondiente.
    - Si detecta una ciudad (de ai.kpi_avg_sales_volume) o palabras como 'oportunidad'/'crecimiento' → usa KPI por defecto.
    - Si no encuentra nada → busca en ai.table_context.
    """

    print("Entrando a kpi_node. Keys de entrada:", list(state.keys()))
    user_input = (state.get("input") or "").lower()
    kpi_info = None

    # Prioridad de detección: ventas > cierre > industria
    for key, val in KPI_ALIASES.items():
        if key in user_input:
            # Prioridad 1: KPIs de ventas o cierre
            if val in ["kpi_avg_sales_volume", "kpi_sales_volume_by_city", "kpi_closing_rate"]:
                kpi_info = {"kpi_name": val, "description": f"KPI detectado (ventas/cierre): {val}"}
                break
            # Prioridad 2: benchmark solo si no hay referencia a ciudad o ventas
            elif val == "industry_benchmarks" and not any(
                w in user_input for w in ["ciudad", "fridley", "ventas", "paramus", "paradise"]
            ):
                kpi_info = {"kpi_name": val, "description": f"KPI detectado (benchmark sectorial): {val}"}
                break



    # detección automática de ciudad o contexto de crecimiento
    if not kpi_info:
        try:
            conn = psycopg2.connect(
                host=os.getenv("DB_HOST"),
                port=os.getenv("DB_PORT"),
                dbname=os.getenv("DB_NAME"),
                user=os.getenv("DB_USER"),
                password=os.getenv("DB_PASSWORD"),
                sslmode="require"
            )
            cur = conn.cursor()
            cur.execute("SELECT DISTINCT LOWER(city) FROM ai.kpi_avg_sales_volume;")
            city_list = [r[0] for r in cur.fetchall()]
            conn.close()
        except Exception as e:
            print(f"o se pudo cargar lista de ciudades: {e}")
            city_list = []

        context_words = ["ciudad", "mercado", "oportunidad", "crecimiento", "ventas", "desempeño"]

        if any(word in user_input for word in city_list + context_words):
            print("Contexto detectado (ciudad u oportunidad). Usando KPI por defecto: kpi_avg_sales_volume")
            kpi_info = {
                "kpi_name": "kpi_avg_sales_volume",
                "description": "Volumen promedio de ventas por ciudad (detección automática)"
            }

    # Búsqueda semántica en la capa si no hay coincidencia previa
    if not kpi_info:
        kpi_info = fetch_kpi_definition(user_input)

    # Si aún no se encontró KPI, devolver error controlado
    if not kpi_info:
        state["error"] = f"No se encontró un KPI relacionado con '{user_input}'."
        print("o se encontró KPI asociado, devolviendo error controlado.")
        return state

    #ejecutar el KPI y actualizar el estado global
    result = execute_kpi_query(kpi_info["kpi_name"])
    print(f"KPI filas devueltas: {len(result.get('rows', []))}")

    new_state = dict(state)
    new_state.update({
        "result_type": "kpi",
        "kpi_name": kpi_info["kpi_name"],
        "description": kpi_info["description"],
        "data": result
    })
    print("Saliendo de kpi_node. Keys de salida:", list(new_state.keys()))
    return new_state


def run_sql_query(prompt: str):
    """Genera y ejecuta una consulta SQL válida o KPI reconocida."""
    llm = get_model()
    sql_prompt = f"""
    Eres un analista experto en datos de RocknBlock.
    Devuelve solo una instrucción SQL ejecutable para PostgreSQL.
    - Si el usuario menciona "KPI", consulta directamente la vista en el esquema ai.
    - Si menciona ventas, leads o jobs, usa el esquema clean.
    - No incluyas explicaciones ni texto adicional.
    ---
    Pregunta del usuario:
    {prompt}
    ---
    """

    sql_response = llm.invoke(sql_prompt)
    sql = sql_response.content.strip().replace("```sql", "").replace("```", "")
    print(f"\nSQL generado por el modelo:\n{sql}\n")

    try:
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT"),
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASSWORD"),
            sslmode="require"
        )
        cur = conn.cursor()
        cur.execute(sql)
        rows = cur.fetchall()
        colnames = [desc[0] for desc in cur.description]
        conn.close()
        return {"sql": sql, "columns": colnames, "rows": rows}
    except Exception as e:
        print(f"Error al ejecutar SQL: {e}")
        return {"error": str(e), "sql": sql, "columns": [], "rows": []}


@traceable(run_type="tool", name="Intent Router")
def intent_router(state):
    """Determina si el usuario pide un KPI o una consulta SQL.
    Respeta la acción detectada previamente (si existe en el estado)."""
    action = state.get("action", "").lower()
    if "sql" in action:
        path = "sql"
    elif "kpi" in action:
        path = "kpi"
    else:
        user_input = state.get("input", "")
        kpi_keywords = [
            "tasa", "promedio", "ratio", "porcentaje",
            "métrica", "indicador", "volumen", "ventas", "kpi", "closing"
        ]
        path = "kpi" if any(word in user_input.lower() for word in kpi_keywords) else "sql"
    print(f"Ruta seleccionada: {path.upper()}")
    new_state = dict(state)
    new_state["path"] = path
    return new_state


@traceable(run_type="tool", name="SQL Node")
def sql_node(state):
    """Ejecuta una consulta SQL generada por LLM."""
    user_input = state["input"]
    result = run_sql_query(user_input)
    new_state = dict(state)
    new_state.update({"result_type": "sql", "data": result})
    return new_state


@traceable(run_type="llm", name="Summary Node")
def summary_node(state):
    """Genera una interpretación ejecutiva y devuelve summary + data."""
    print("Entrando a summary_node con keys:", list(state.keys()))

    llm = get_model()
    result_type = state.get("result_type", "unknown")
    data = state.get("data", {})

    if not data or not data.get("rows"):
        print("Advertencia: no se encontraron datos en el estado.")
        summary_text = "No se encontraron resultados o el dataset está vacío."
        return {
            "result_type": result_type,
            "data": data if isinstance(data, dict) else {},
            "summary": summary_text,
        }

    print("Datos enviados al LLM:", {"columns": data.get("columns"), "rows_len": len(data.get("rows", []))})
    prompt = f"""
    Eres un analista senior de RocknBlock. Genera una interpretación ejecutiva clara del siguiente resultado ({result_type}):
    {data}
    """
    summary = llm.invoke(prompt).content
    print("Interpretación generada correctamente.")
    return {
        "result_type": result_type,
        "data": data,
        "summary": summary,
    }

# ======================
# Construcción del grafo
# ======================

def build_graph():
    """Define la estructura principal del flujo LangGraph."""
    from typing import TypedDict, Optional

    class AgentState(TypedDict, total=False):
        input: str
        path: Optional[str]
        result_type: Optional[str]
        kpi_name: Optional[str]
        description: Optional[str]
        data: Optional[dict]
        summary: Optional[str]
        error: Optional[str]

    g = StateGraph(AgentState)

    # Nodos del flujo
    g.add_node("router", intent_router)
    g.add_node("sql_node", sql_node)
    g.add_node("kpi_node", kpi_node)
    g.add_node("summary_node", summary_node)

    # Aseguramos que router siempre propague el path
    def route_selector(state):
        path = state.get("path", "")
        if path not in ("sql", "kpi"):
            print(f"uta no definida en el estado. Default = 'sql'")
            return "sql"
        return path

    g.add_conditional_edges(
        "router",
        route_selector,
        {"sql": "sql_node", "kpi": "kpi_node"}
    )

    # Asegurar propagación completa del estado
    g.add_edge("sql_node", "summary_node")
    g.add_edge("kpi_node", "summary_node")
    g.add_edge("summary_node", END)
    g.set_entry_point("router")

    return g

# ======================
# Ejecución directa
# ======================

if __name__ == "__main__":
    import sys

    query = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else "Total de ventas por ciudad"
    graph = build_graph().compile()

    print(f"\nEjecutando consulta: {query}\n")

    try:
        result = graph.invoke({"input": query})
        print("\n=== Interpretación ejecutiva ===\n")
        print(result.get("summary") or "No se generó resumen.")
        print("\n=== Resultado bruto ===\n")
        print(result.get("data") or "Sin datos.")
    except Exception as e:
        print(f"Error al ejecutar el flujo: {e}")
